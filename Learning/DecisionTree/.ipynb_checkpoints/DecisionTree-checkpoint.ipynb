{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树三种算法\n",
    "- ID3：特征划分基于信息增益  \n",
    "- C4.5：特征划分基于信息增益比\n",
    "- CART：特征划分基于基尼指数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树的流程为：\n",
    "\n",
    "　　(1)输入需要分类的数据集和类别标签和靶标签。\n",
    "\n",
    "　　(2)检验数据集是否只有一列，或者是否最后一列(靶标签数据默认放到最后一列)只有一个水平(唯一值)。\n",
    "\n",
    "　　　　是：返回唯一值水平或者占比最大的那个水平\n",
    "\n",
    "　　(3)调用信息增益公式，计算所有节点的信息增益，得到最大信息增益所对应的类别标签。\n",
    "\n",
    "　　(4)建立决策树字典用以保存当次叶节点数据信息。\n",
    "\n",
    "　　(5)进入循环：\n",
    "\n",
    "　　　　按照该类别标签的不同水平，依次计算子数据集；\n",
    "\n",
    "　　　　对子数据集重复(1),(2),(3),(4),(5), (6)步。\n",
    "\n",
    "　　(6)返回决策树字典。\n",
    "\n",
    "决策树实际上是一个大的递归函数，其结果是一个多层次的字典。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# class LoadDataSet(object):\n",
    "#     def load_dataSet(self):\n",
    "#         data = pd.read_csv('./ID3data.txt', sep='\\t', header=None)\n",
    "#         data.rename(columns={0: 'age', 1: 'income', 2: 'student', 3: 'reputation', 4: 'purchase'},inplace=True)\n",
    "#         return data\n",
    "\n",
    "# # 用来加载和存储训练的模型\n",
    "# class TreeHandler(object):\n",
    "#     def __init__(self):\n",
    "#         self.tree = None\n",
    "#     def save(self, tree):\n",
    "#         self.tree = tree\n",
    "#         with open('tree.txt', mode='w', encoding='utf-8') as f:\n",
    "#             tree = json.dumps(tree, indent=\" \", ensure_ascii=False) # ensure_ascii=False 可以输出中文\n",
    "#             f.write(tree)\n",
    "#     def load(self, file):\n",
    "#         with open(file, mode='r', encoding='utf-8') as f:\n",
    "#             tree = f.read()\n",
    "#             self.tree = json.loads(tree)\n",
    "#         return self.tree\n",
    "    \n",
    "# ID3\n",
    "class ID3Tree(object):\n",
    "    def __init__(self):\n",
    "        self.__count = 0\n",
    "        self.tree = {}\n",
    "        self.InfoGain = {}\n",
    "    def _entropy(self, dataSet):\n",
    "        # 计算给定数据集的熵\n",
    "        labels = dataSet.columns.tolist()\n",
    "        # 统计分类标签不同水平的值\n",
    "        level_count = dataSet[labels[-1]].value_counts().to_dict()\n",
    "        entropy = 0\n",
    "        for level, nums in level_count.items():\n",
    "            prob = float(nums) / dataSet.shape[0]\n",
    "            entropy += -prob * np.log2(prob)\n",
    "        return entropy\n",
    "    def _split_dataSet(self, dataSet, best_label, level):\n",
    "        # 根据给定的特征label和其分类level来获取新的子数据集\n",
    "        subdata = dataSet[dataSet[best_label] == level]\n",
    "        \n",
    "        # 去掉best_label这一列，重置索引,drop=True去掉原索引\n",
    "        del subdata[best_label]\n",
    "        subdata.reset_index(drop=True, inplace=True)\n",
    "        return subdata\n",
    "        \n",
    "    def _best_split(self, dataSet):\n",
    "        # 计算每个特征的信息增益\n",
    "        best_infoGain = 0.0\n",
    "        best_label = None\n",
    "        \n",
    "        labels = dataSet.columns.tolist()[:-1]\n",
    "        Entropy_S = self._entropy(dataSet) # 把标签的熵\n",
    "        # label是新加的特征，level是label下的分类\n",
    "        for index, label in enumerate(labels):\n",
    "            levels = dataSet[label].unique().tolist()\n",
    "            label_entropy = 0.0\n",
    "            for level in levels:\n",
    "                level_data = dataSet[dataSet[label] == level]\n",
    "                prob = level_data.shape[0] / dataSet.shape[0]\n",
    "                label_entropy += prob * self._entropy(level_data)\n",
    "            infoGain = Entropy_S - label_entropy\n",
    "            if infoGain > best_infoGain:\n",
    "                best_infoGain = infoGain\n",
    "                best_label = label\n",
    "            self.InfoGain.setdefault(self.__count, {}) # 保存{__count: {label1: infoGain1, label2: infoGain2, ...}}\n",
    "            self.InfoGain[self.__count][label] = infoGain\n",
    "        self.__count += 1\n",
    "        return best_label\n",
    "    \n",
    "    def _top_amount_level(self, target_list):\n",
    "        level_count = target_list.unique().value_counts().to_dict()\n",
    "        sorted_level_count = sorted(level_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_level_count[0][0]\n",
    "    \n",
    "    def mktree(self, dataSet):\n",
    "        target_list = dataSet.iloc[:, -1] # 靶标签的那一列数据\n",
    "#         # 程序终止条件一：靶标签在该数据集上只有一个值(全部归为1类)，返回该值\n",
    "#         if target_list.unique().shape[0] == 1:\n",
    "#             return target_list[0]\n",
    "        \n",
    "#         # 程序终止条件二：数据集只剩下靶标签这一列，返回靶标签上数量最多的水平,这是将所有的都归为这一类，少数服从多数\n",
    "#         if dataSet.shape[0] == 1:\n",
    "#             return self._top_amount_level(dataSet)\n",
    "        \n",
    "#         # 递归\n",
    "#         # 选择最佳分类特征\n",
    "#         best_label = self._best_split(dataSet)\n",
    "        \n",
    "#         # 在选择的特征下面选择分类\n",
    "#         best_label_levels = dataSet[best_label].unique().tolist()\n",
    "#         tree[best_label] = {} # 生成字典，保存树分类信息\n",
    "#         for level in best_label_levels:\n",
    "#             level_subdata = self._split_dataSet(dataSet, best_label, level) #params: 原数据， 信息增益最大的特征， 特性下的分类level\n",
    "#             tree[best_label][level] = self.mktree(level_subdata)\n",
    "#         return tree\n",
    "        target_list = dataSet.iloc[:, -1] # 靶标签的那一列数据\n",
    "        # 程序终止条件一：靶标签在该数据集上只有一个值(全部归为1类)，返回该值\n",
    "        if target_list.unique().shape[0] <= 1:\n",
    "            return target_list[0]\n",
    "        \n",
    "        # 程序终止条件二：数据集只剩下靶标签这一列，返回靶标签上数量最多的水平,这是将所有的都归为这一类，少数服从多数\n",
    "        if dataSet.shape[0] == 1:\n",
    "            return self._top_amount_level(dataSet)\n",
    "        \n",
    "        # 递归\n",
    "        # 选择最佳分类特征\n",
    "        best_label = self._best_split(dataSet)\n",
    "        \n",
    "        # 在选择的特征下面选择分类\n",
    "        best_label_levels = dataSet[best_label].unique().tolist()\n",
    "        self.tree = {best_label: {}} # 生成字典，保存树分类信息\n",
    "        for level in best_label_levels:\n",
    "            level_subdata = self._split_dataSet(dataSet, best_label, level) #params: 原数据， 信息增益最大的特征， 特性下的分类level\n",
    "            self.tree[best_label] = {level: self.mktree(level_subdata)}\n",
    "    \n",
    "    def predict(self, tree, labels, test_samples):\n",
    "        '''\n",
    "        tree: trained model, a dict\n",
    "        labels: all features\n",
    "        '''\n",
    "        firstStr = list(tree.keys())[0]\n",
    "        secondDict = tree[firstStr]\n",
    "        featIndex = labels.index(firstStr) # 找到第一个特征label在labels上的索引\n",
    "        for key in secondDict.keys():\n",
    "            if test_samples[featIndex] == key:\n",
    "                if secondDict[key].__class__.__name__ == \"dict\":\n",
    "                    classLabel = self.predict(secondDict[key], labels, test_samples)\n",
    "                else:\n",
    "                    classLabel = secondDict[key]\n",
    "    \n",
    "    def predict(self, tree, labels, test_samples):\n",
    "        '''\n",
    "        tree: trained model, a dict\n",
    "        labels: all features\n",
    "        '''\n",
    "        firstStr = list(tree.keys())[0]\n",
    "        secondDict = tree[firstStr]\n",
    "        featIndex = labels.index(firstStr) # 找到第一个特征label在labels上的索引\n",
    "        for key in secondDict.keys():\n",
    "            if test_samples[featIndex] == key:\n",
    "                if secondDict[key].__class__.__name__ == \"dict\":\n",
    "                    classLabel = self.predict(secondDict[key], labels, test_samples)\n",
    "                else:\n",
    "                    classLabel = secondDict[key]\n",
    "        return classLabel\n",
    "        \n",
    "    def _unit_test(self):\n",
    "        \"\"\"用于测试_entropy函数\"\"\"\n",
    "        data = [[1, 1, \"yes\"], \n",
    "                [1, 1, \"yes\"],\n",
    "                [1, 0, \"no\"],\n",
    "                [0, 1, \"no\"],\n",
    "                [0, 1, \"no\"],]\n",
    "        data = pd.DataFrame(data=data, columns=[\"a\", \"b\", \"c\"])\n",
    "        self.tree = self.mktree(self.dataSet)\n",
    "        labels = [\"age\", \"income\", \"student\", \"reputation\"]\n",
    "        test_sample = [0, 1, 0, 1]   # [0, 1, 0, 0, \"no\"]\n",
    "        output = self.predict(self.tree, labels, test_sample)\n",
    "        print(\"The truth class is %s, The ID3Tree outcome is %s.\" % (\"no\", output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>student</th>\n",
       "      <th>reputation</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  student  reputation purchase\n",
       "0    0       0        0           0       no\n",
       "1    0       0        0           0       no\n",
       "2    0       0        0           0       no\n",
       "3    0       0        0           0       no\n",
       "4    0       0        0           0       no"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./ID3data.txt', sep='\\t', header=None)\n",
    "data.rename(columns={0: 'age', 1: 'income', 2: 'student', 3: 'reputation', 4: 'purchase'},inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': {2: None}, 'reputation': {1: 'no'}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ID3Tree()\n",
    "model.mktree(data)\n",
    "model.tree\n",
    "# print(model.tree)\n",
    "\n",
    "# labels = model.predict(labels=[\"age\", \"income\", \"student\", \"reputation\"], test_samples=[0, 1, 0, 1])\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': {0: {'student': {0: 'no', 1: 'yes'}},\n",
       "  1: 'yes',\n",
       "  2: {'reputation': {0: 'yes', 1: 'no'}}}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ID3Tree()\n",
    "model.mktree(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义节点类 二叉树\n",
    "class Node:\n",
    "    def __init__(self, root=True, label=None, feature_name=None, feature=None):\n",
    "        self.root = root\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "        self.result = {'label:': self.label, 'feature': self.feature, 'tree': self.tree}\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}'.format(self.result)\n",
    "\n",
    "    def add_node(self, val, node):\n",
    "        self.tree[val] = node\n",
    "\n",
    "    def predict(self, features):\n",
    "        if self.root is True:\n",
    "            return self.label\n",
    "        return self.tree[features[self.feature]].predict(features)\n",
    "    \n",
    "class DTree:\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self._tree = {}\n",
    "\n",
    "    # 熵\n",
    "    @staticmethod\n",
    "    def calc_ent(datasets):\n",
    "        data_length = len(datasets)\n",
    "        label_count = {}\n",
    "        for i in range(data_length):\n",
    "            label = datasets[i][-1]\n",
    "            if label not in label_count:\n",
    "                label_count[label] = 0\n",
    "            label_count[label] += 1\n",
    "        ent = -sum([(p/data_length)*log(p/data_length, 2) for p in label_count.values()])\n",
    "        return ent\n",
    "\n",
    "    # 经验条件熵\n",
    "    def cond_ent(self, datasets, axis=0):\n",
    "        data_length = len(datasets)\n",
    "        feature_sets = {}\n",
    "        for i in range(data_length):\n",
    "            feature = datasets[i][axis]\n",
    "            if feature not in feature_sets:\n",
    "                feature_sets[feature] = []\n",
    "            feature_sets[feature].append(datasets[i])\n",
    "        cond_ent = sum([(len(p)/data_length)*self.calc_ent(p) for p in feature_sets.values()])\n",
    "        return cond_ent\n",
    "\n",
    "    # 信息增益\n",
    "    @staticmethod\n",
    "    def info_gain(ent, cond_ent):\n",
    "        return ent - cond_ent\n",
    "\n",
    "    def info_gain_train(self, datasets):\n",
    "        count = len(datasets[0]) - 1\n",
    "        ent = self.calc_ent(datasets)\n",
    "        best_feature = []\n",
    "        for c in range(count):\n",
    "            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))\n",
    "            best_feature.append((c, c_info_gain))\n",
    "        # 比较大小\n",
    "        best_ = max(best_feature, key=lambda x: x[-1])\n",
    "        return best_\n",
    "\n",
    "    def train(self, train_data):\n",
    "        \"\"\"\n",
    "        input:数据集D(DataFrame格式)，特征集A，阈值eta\n",
    "        output:决策树T\n",
    "        \"\"\"\n",
    "        _, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[:-1]\n",
    "        # 1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T\n",
    "        if len(y_train.value_counts()) == 1:\n",
    "            return Node(root=True,\n",
    "                        label=y_train.iloc[0])\n",
    "\n",
    "        # 2, 若A为空，则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T\n",
    "        if len(features) == 0:\n",
    "            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "\n",
    "        # 3,计算最大信息增益 同5.1,Ag为信息增益最大的特征\n",
    "        max_feature, max_info_gain = self.info_gain_train(np.array(train_data))\n",
    "        max_feature_name = features[max_feature]\n",
    "\n",
    "        # 4,Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T\n",
    "        if max_info_gain < self.epsilon:\n",
    "            return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0])\n",
    "\n",
    "        # 5,构建Ag子集\n",
    "        node_tree = Node(root=False, feature_name=max_feature_name, feature=max_feature)\n",
    "\n",
    "        feature_list = train_data[max_feature_name].value_counts().index\n",
    "        for f in feature_list:\n",
    "            sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([max_feature_name], axis=1)\n",
    "\n",
    "            # 6, 递归生成树\n",
    "            sub_tree = self.train(sub_train_df)\n",
    "            node_tree.add_node(f, sub_tree)\n",
    "\n",
    "        # pprint.pprint(node_tree.tree)\n",
    "        return node_tree\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        self._tree = self.train(train_data)\n",
    "        return self._tree\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self._tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART(Classification And Regression Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CART分类树\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'SimHei'\n",
    "plt.rcParams['axis.unicode_minus'] = False\n",
    "\n",
    "decisionNode = dict(boxstyle='swatooth', fc='0.8')\n",
    "leafNode = dict(boxstyle='round4', fc='0.8')\n",
    "arraw_args = dict(arrowstyle='<-')\n",
    "\n",
    "# calculate gini\n",
    "def calcGini(dataSet):\n",
    "    y_labels = np.unique(dataSet[:, -1])\n",
    "    numSamples = len(dataSet)\n",
    "    y_p = {} # 每一个分类的概率\n",
    "    gini = 1 # gini = 1 - p_i**2\n",
    "    for label in y_labels:\n",
    "        y_p[label] = len(dataSet[dataSet[:, -1] == label]) / numSamples\n",
    "        gini -= y_p[label] ** 2\n",
    "    return gini\n",
    "\n",
    "# 划分数据集\n",
    "def splitDataSet(dataSet, feat, level, types=1):\n",
    "    if types == 1: # 使用此特征feat中的level进行划分\n",
    "        subDataSet = dataSet[dataSet[:, feat] == level]\n",
    "    elif types == 2:\n",
    "        subDataSet = dataSet[dataSet[:, feat] != level]\n",
    "    return subDataSet, len(subDataSet)\n",
    "\n",
    "# 计算Gini指数，选择最好的特征划分数据集，返回最佳特征下标和最佳分区，Gini指数字典\n",
    "def chooseBestFeature(dataSet, types='Gini'):\n",
    "    numSamples = dataSet.shape[0]\n",
    "    numFeatures = dataSet.shape[1] - 1\n",
    "    bestFeature = -1\n",
    "    columnFeatGini = {}\n",
    "    for i in range(numFeatures):\n",
    "        d = dataSet[:, i].value_counts().to_dict() # {level1: count1, level2: count2, ...}\n",
    "        for level, n in d.items():\n",
    "            conditionGini = 0.0 # 类似条件熵\n",
    "            bestFlag = 1.00001\n",
    "            subdataSet1, sublen1 = splitDataSet(dataSet, i, level, 1)\n",
    "            subDataSet2, sublen2 = splitDataSet(dataSet, i, level, 2)\n",
    "            if (sublen1 / numSamples) * calcGini(subdataSet1) == 0: # 表示这一个特征已经所有的level值都归为1类 \n",
    "                bestFlag = 1\n",
    "            conditionGini += (sublen1 / numSamples) * calcGini(subdataSet1) + \\\n",
    "                             (sublen2 / numSamples) * calcGini(subdataSet2) \n",
    "\n",
    "            columnFeatGini['%d_%s'%(i, level)] = conditionGini * bestFlag\n",
    "    bestFeature = min(columnFeatGini, key=columnFeatGini.get) # 找到字典最小值的key\n",
    "    return bestFeature,columnFeatGini\n",
    "\n",
    "def createTree(dataSet, feat, types='Gini'):\n",
    "    y_labels = np.unique(dataSet[:, -1])\n",
    "\n",
    "    #1.如果数据集D中的所有实例都属于同一类label，则T为单节点树，将label作为该节点的类标记，返回T\n",
    "    if len(set(y_labels)) == 1:\n",
    "        return y_labels[0]\n",
    "\n",
    "    #2.若只剩下label列，返回label中出现次数最大的level，返回T\n",
    "    if dataSet.shape[1] == 1:\n",
    "        label_dict = dataSet.value_counts().to_dict()\n",
    "        return max(label_dict, key=label_dict.get)\n",
    "\n",
    "    #3.CART,选择Gini指数最小的特征bestFeature进行划分\n",
    "    bestFeature, columnFeatGini = chooseBestFeature(dataSet, types)\n",
    "\n",
    "    bestFeatureLabel = feat[int(bestFeature.split('_')[0])] # feature val\n",
    "    bestFeatureIndex = int(bestFeature.split('_')[0]) # index\n",
    "    bestFeatureLevel = bestFeature.split('_')[1]\n",
    "    decisionTree = {bestFeatureLabel: {}}\n",
    "\n",
    "    # 使用bestFeauture进行划分，产生两个节点\n",
    "    y_label_split_dict = dataSet[ dataSet[:, bestFeatureIndex] == bestFeatureLevel][:, -1].value_counts().to_dict()\n",
    "    y_leaf = max(y_label_split_dict, key=y_label_split_dict.get) # yes | no\n",
    "    decisionTree[bestFeatureLabel][bestFeatureLevel] = y_leaf # 左枝叶子值\n",
    "\n",
    "    #4. 删除此最优划分数据样本，用其他样本递归1-3，得到树\n",
    "    subDataSet = np.delete(dataSet, bestFeatureIndex, axis=1)\n",
    "    feat.pop(bestFeatureIndex)\n",
    "    subfeat = feat\n",
    "    # 判断右支类型，划分后左枝右枝不定,且CART树只有两个分类\n",
    "    y1 = y_labels[0]\n",
    "    y2 = y_labels[1]\n",
    "    if y_leaf == y1:\n",
    "        decisionTree[bestFeatureLabel][y2] = {}\n",
    "        decisionTree[bestFeatureLabel][y2] = createTree(subDataSet, subfeat, types)\n",
    "    elif y_leaf == y2:\n",
    "        decisionTree[bestFeatureLabel][y1] = {}\n",
    "        decisionTree[bestFeatureLabel][y1] = createTree(subDataSet, subfeat, types)\n",
    "\n",
    "    return decisionTree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
